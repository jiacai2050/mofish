[{"time":1765212871,"type":"story","descendants":322,"title":"Microsoft has a problem: lack of demand for its AI products","id":46194615,"score":379,"url":"https://www.windowscentral.com/artificial-intelligence/microsoft-has-a-problem-nobody-wants-to-buy-or-use-its-shoddy-ai","by":"mohi-kalantari","summary":"## 微软人工智能战略面临挑战：谷歌Gemini崛起，Copilot市场份额受损\n\n**概述：**\n\n根据近期报告和市场数据，微软在人工智能领域的战略正在面临挑战。尽管在Satya Nadella的领导下，微软早期在人工智能领域取得了一些进展，但现在市场份额和客户满意度正在下降，谷歌Gemini正在迅速崛起。\n\n**关键点：**\n\n* **Copilot市场份额下滑：** FirstPageSage的报告显示，截至2025年12月初，Microsoft Copilot的市场份额为14.1%，而Google Gemini的市场份额为13.4%，且Gemini的用户增长速度明显高于Copilot（分别为12%和2%）。ChatGPT仍然是领先者，份额为61.3%，但市场份额也在下降。\n* **OpenAI面临困境：** 微软深度依赖OpenAI，但OpenAI的商业模式面临质疑，债务问题严重。这使得微软面临风险，因为其业务与OpenAI的未来紧密相连。\n* **产品质量问题：** 微软的人工智能产品常常被批评为“半成品”，缺乏深思熟虑，且在功能和用户体验方面落后于竞争对手。例如，Pixel手机上的照片编辑功能远超Windows系统上的Microsoft Photos应用，Copilot在Microsoft 365的应用也表现不佳。\n* **成本效益问题：** 报告指出，agentic AI工具需要频繁的人工干预，这使得它们成本效益较低。微软似乎对此并不在意。\n* **依赖NVIDIA：** 微软在数据中心方面高度依赖昂贵的NVIDIA技术，而谷歌则积极投资于整个技术栈的自主研发。\n* **未来展望：** 微软正在尝试开发自己的语言模型（Maia和Cobalt）和芯片，以减少对NVIDIA和OpenAI的依赖。然而，微软在执行长期计划方面存在历史问题。\n\n**总结：**\n\n微软在人工智能领域面临的挑战，主要源于产品质量问题、对外部供应商的过度依赖以及缺乏对客户需求的关注。尽管微软早期在人工智能领域取得了一些进展，但如果不能解决这些问题，微软的未来可能会沦为NVIDIA服务器的经销商，而非技术创新者。 谷歌Gemini的崛起，以及OpenAI的困境，都对微软的人工智能战略提出了严峻的挑战。"},{"time":1765239406,"type":"story","descendants":106,"title":"The universal weight subspace hypothesis","id":46199623,"score":305,"url":"https://arxiv.org/abs/2512.05117","by":"lukeplato","summary":"## 深度神经网络的通用参数子空间：大规模经验证据\n\n本文研究了在不同任务上训练的深度神经网络的参数结构，并发现它们展现出惊人相似的低维参数子空间。 这项研究提供了大规模的经验证据，证明了神经网络无论初始化、任务或领域如何，都会系统地收敛到共享的谱子空间。\n\n**主要发现：**\n\n*   **共享谱子空间：** 通过对超过1100个模型（包括500个Mistral-7B LoRAs、500个视觉Transformer和50个LLaMA-8B模型）进行模式化谱分析，研究人员发现存在通用的子空间，这些子空间能够捕捉到绝大部分的方差，且仅需要少数的主方向。\n*   **稀疏、联合子空间：**  通过对各种架构在广泛任务和数据集上训练的权重矩阵进行谱分解，研究人员识别出稀疏、联合的子空间，这些子空间在不同的架构和任务中被持续利用。\n*   **内在组织结构：**  这些发现为理解深度网络内部信息的内在组织结构提供了新的见解。\n\n**研究意义：**\n\n*   **减少数据和计算资源需求：**  研究提出了一种可能，即可以在不需要大量数据和计算资源的情况下发现这些通用的子空间。\n*   **潜在应用：** 这种内在结构具有重大的影响，可以促进模型可重用性、多任务学习、模型合并以及开发训练和推理高效算法。\n*   **降低碳足迹：**  最终，这可能有助于降低大规模神经网络的碳足迹。\n\n**关键信息总结：**\n\n*   **研究对象：** 深度神经网络（包括Mistral-7B LoRAs、Vision Transformers和LLaMA-8B模型）\n*   **研究方法：** 模式化谱分析和谱分解\n*   **核心发现：** 神经网络在不同任务上训练时，会收敛到共享的低维参数子空间，这些子空间普遍存在且被持续利用。\n*   **潜在影响：** 促进模型可重用性、多任务学习、模型合并，并降低大规模神经网络的碳足迹。\n*   **版本信息：**  该论文共有37页，目前发布了版本v2 (arXiv:2512.05117v2)。\n"},{"time":1765219863,"type":"story","descendants":103,"title":"Jepsen: NATS 2.12.1","id":46196105,"score":274,"url":"https://jepsen.io/analyses/nats-2.12.1","by":"aphyr","summary":"## NATS JetStream 数据一致性测试结果总结\n\nJepsen 独立研究团队对 NATS JetStream (版本 2.12.1) 的数据一致性进行了测试，发现存在数据丢失问题，尤其是在少数节点出现数据文件截断或损坏、协调的电源故障或单个节点操作系统崩溃并伴随网络延迟或进程暂停等情况下。\n\n**背景:**\n\n*   NATS 是一个分布式流系统。\n*   常规 NATS 流提供“尽力而为”的交付保证，而 JetStream 子系统则保证至少一次交付。\n*   JetStream 使用 Raft 共识算法在节点之间复制数据，承诺“至少一次”交付，并保证消息的完全有序。\n*   JetStream 的设计目标是“自我修复并始终可用”，并声称具有线性一致性。\n\n**测试设计:**\n\n*   使用 Jepsen 测试库和 JNATS (Java 客户端) 对 NATS JetStream 进行测试。\n*   测试环境通常包含三个或五个节点，并使用单 JetStream 流，目标复制因子为五。\n*   测试注入了各种故障，包括进程暂停、崩溃、网络分区、丢包、单比特错误和数据文件截断。\n*   使用了 LazyFS 文件系统模拟电源故障。\n*   测试测量了 JetStream 的至少一次语义，以及节点之间消息的差异（split-brain）。\n\n**主要发现:**\n\n*   **2.10.22 版本数据总丢失 (#6888):** 在 2.10.20 到 2.10.22 版本中，进程崩溃可能导致整个 JetStream 流及其所有数据丢失。此问题已在 2.10.23 版本中修复。\n*   **.blk 文件损坏导致数据丢失 (#7549):** 数据文件（.blk）的单比特错误或截断可能导致集群丢失大量已确认的写入。 即使只有少数节点出现文件损坏，也会发生此问题。\n*   **快照文件损坏导致数据丢失 (#7556):** 截断或引入快照文件的单比特错误可能导致节点删除整个流的数据文件，导致集群无法恢复。\n*   **延迟 fsync 策略 (#7564):** JetStream 默认情况下每两分钟才将数据刷新到磁盘，但在确认消息时立即发送确认。 这种延迟可能导致在节点出现电源故障、内核崩溃或硬件故障等情况下，已确认的写入丢失。NATS 已在文档中记录了此风险。\n*   **单个操作系统崩溃导致数据丢失和 split-brain (#7567):** 单个操作系统崩溃，结合进程暂停或网络分区，可能导致已确认消息丢失，并导致持续的 split-brain 现象。\n\n**讨论:**\n\n*   尽管 JetStream 声称具有线性一致性，但 CAP 定理表明线性一致性系统无法始终可用。\n*   Jepsen 建议 NATS 更改默认的 `fsync` 值，或者明确记录 JetStream 在某些故障情况下可能丢失数据。\n*   测试表明，即使在节点数量足够的情况下，单个操作系统崩溃也可能导致数据丢失。\n\n**总结:**\n\nJepsen 的测试结果表明，NATS JetStream 在某些情况下存在数据一致性问题。虽然 NATS 已经修复了一些问题，但仍有一些问题需要进一步调查和解决。用户应该了解这些潜在风险，并根据自己的需求配置 JetStream，以确保数据安全。"},{"time":1765219707,"type":"story","descendants":149,"title":"Deep dive on Nvidia circular funding","id":46196076,"score":270,"url":"https://philippeoger.com/pages/deep-dive-into-nvidias-virtuous-cycle","by":"jeanloolz","summary":"## NVIDIA、OpenAI、Oracle 的“敌对合作”关系：深度解析\n\n本文分析了NVIDIA在人工智能领域的地位、与OpenAI和Oracle之间的复杂关系，以及围绕“循环融资”的争议。作者通过剖析NVIDIA第三季度财报，结合OpenAI和Oracle的最新动态，揭示了AI硬件市场潜在的风险与机遇。\n\n**核心观点：**\n\n*   **NVIDIA业绩亮眼，但存在隐忧：**NVIDIA第三季度营收增长62%，数据中心业务占比高达90%，业绩表现强劲。然而，作者发现了一些潜在问题：\n    *   **现金流缺口：**净利润高达319亿美元，但经营现金流仅238亿美元，存在8亿美元缺口。\n    *   **库存积压：**库存量近翻倍，达到198亿美元，可能导致资金压力。\n    *   **应收账款周期延长：**应收账款天数增加至53天，表明NVIDIA可能为客户提供巨额信贷以维持业务增长。\n*   **“循环融资”质疑：**作者详细分析了Michael Burry提出的“循环融资”质疑，并绘制了相应的图表：\n    1.  NVIDIA向OpenAI投资数十亿美元。\n    2.  OpenAI与Oracle签订3000亿美元的云服务合同（Project Stargate）。\n    3.  Oracle为履行合同，向NVIDIA采购400亿美元的GB200 GPU。\n    *   作者认为，若NVIDIA停止投资OpenAI，OpenAI和Oracle的合作关系可能面临挑战，部分营收可能存在不稳定性。监管机构（如美国司法部）正在对此进行调查。\n*   **OpenAI摆脱NVIDIA依赖的举动：**OpenAI正在积极构建自主供应链，以减少对NVIDIA的依赖：\n    *   **Project Stargate:** 不仅是数据中心，还包含定制硬件。\n    *   **直接采购HBM：**OpenAI直接从Samsung和SK Hynix采购DRAM晶圆，绕过NVIDIA的供应链。\n    *   **人才涌入：**OpenAI挖走Google的TPU负责人Richard Ho，以及来自Apple的40多名硬件工程师。\n    *   **Broadcom合作：**OpenAI计划利用NVIDIA GPU进行模型训练，但使用自主研发的芯片进行推理，以降低成本。\n*   **Oracle收购Groq的潜在机会：**作者认为Oracle应考虑收购初创公司Groq，Groq专注于提供更快、更便宜的AI推理芯片。\n    *   **HBM短缺的应对：**Groq的架构依赖SRAM，而非HBM，可以有效避免HBM供应短缺问题。\n    *   **降低成本：**Oracle租用NVIDIA芯片的利润率仅为14%，收购Groq可以降低成本，提高利润率。\n    *   **对OpenAI支持：**Groq能够为OpenAI提供更高效的推理能力。\n*   **最终思考：**作者认为NVIDIA、OpenAI和Oracle之间的关系复杂，存在潜在的利益冲突和权力博弈。  NVIDIA是否知晓OpenAI绕过其供应链的举动？ NVIDIA是否在限制Oracle的自主性？ OpenAI未来将采用何种芯片？  AI硬件市场竞争激烈，未来发展充满不确定性。\n\n**总结：**\n\n本文深入剖析了NVIDIA在AI领域的生态地位以及其与OpenAI、Oracle之间的复杂关系，揭示了潜在的风险和挑战。作者的分析视角独特，观点犀利，引发了对AI硬件市场未来的思考。"},{"time":1765223040,"type":"story","descendants":95,"title":"Icons in Menus Everywhere – Send Help","id":46196688,"score":237,"url":"https://blog.jim-nielsen.com/2025/icons-in-menus/","by":"ArmageddonIt","summary":"## 菜单图标泛滥：对设计趋势的反思 (菜单图标泛滥：对设计趋势的反思)\n\n这篇文章主要探讨了菜单中过度使用图标的问题，作者对“默认给每个菜单项添加图标”的设计理念表示不满，并以 macOS Tahoe 和 Google Sheets 为例进行了分析。\n\n**主要观点：**\n\n*   **反对默认图标化：** 作者认为，不应该将“给每个菜单项添加图标”作为默认的设计方法，这容易导致设计师为了填充空间而随意添加图标，而忽略了图标是否能真正提升用户体验。\n*   **macOS Tahoe 的变化：**  macOS Tahoe 系统将图标引入到各个菜单中，但图标的使用并不统一，导致一些菜单项有图标，而相邻的菜单项没有，缺乏明确的逻辑和理由。\n*   **图标使用不一致：**  Safari 和 Mail 等应用程序的菜单中，图标、复选框（表示切换状态）的组合方式也显得混乱，难以理解。作者设想了一个实验，移除菜单文字，观察用户能否正确识别菜单项，以此来检验图标的有效性。\n*   **成功的图标示例：**  Finder 窗口菜单中的图标示例证明了图标在特定情况下确实可以有效地提高可用性，例如，通过视觉方式清晰地展示窗口对齐方式。\n*   **苹果自身指南的背离：**  苹果公司之前的 Human Interface Guidelines (HIG) 明确指出，菜单中不应使用任意图标，因为它们会增加视觉混乱，并可能让用户感到困惑。而 macOS Tahoe 的设计恰恰违背了这一原则。\n*   **结论：** 作者对菜单中无处不在的图标感到厌倦，并认为现在更难说服人们采用“默认不使用图标”的设计方法。\n\n**总结：**\n\n文章的核心在于质疑过度使用菜单图标的趋势，强调了在设计中应该考虑图标的实际价值，而不是盲目地追求视觉上的填充。作者呼吁设计师在决定是否使用图标时，需要仔细评估其对用户体验的影响，并参考苹果公司之前的设计指南。"},{"time":1765211648,"type":"story","descendants":55,"title":"Let's put Tailscale on a jailbroken Kindle","id":46194337,"score":232,"url":"https://tailscale.com/blog/tailscale-jailbroken-kindle","by":"Quizzical4230","summary":"## 总结：在Kindle上安装Tailscale，解锁更多可能性\n\n这篇文章介绍了如何在越狱的Kindle设备上安装Tailscale，从而解锁更多功能和可能性。\n\n**核心内容：**\n\n* **越狱Kindle：** 越狱是指移除设备制造商对软件的限制，获得类似root权限，允许运行未经批准的软件并进行更多操作。文章提到，目前可以通过基于Amazon广告的“AdBreak”解锁方案越狱较新版本的Kindle设备。\n* **Tailscale的作用：** Tailscale并非越狱Kindle的必需品，但能极大地提升使用体验，主要优势包括：\n    * **永久IP地址：** 像其他Tailscale设备一样，Kindle拥有固定的IP地址。\n    * **便捷的SSH访问：** 通过magicDNS，可以直接使用`ssh root@kindle`命令访问Kindle。\n    * **Taildrop文件传输：** 方便快捷地将文件传输到Kindle的指定目录。\n    * **搭建自托管Calibre Web库：** 安全地从任何地方通过KOReader访问自托管的Calibre Web电子书库。\n* **安装步骤：**\n    1. **检查设备：** 确认Kindle型号和固件版本，查看是否有可用的越狱方法。\n    2. **越狱：** 按照Kindle Modding Wiki的指南进行越狱。\n    3. **安装KUAL和MRPI：** 这两个应用是安装其他应用的基础。\n    4. **安装Tailscale：** 下载Tailscale Linux二进制文件，并将其放置在KUAL/Kindle仓库的指定目录。\n    5. **配置认证密钥：** 在Tailscale管理控制台生成认证密钥，并将其添加到Kindle的配置文件中。\n    6. **启动Tailscale：** 通过KUAL启动Tailscaled和Tailscale服务。\n\n**关键点：**\n\n* **风险提示：** 越狱存在设备变砖和失去保修的风险。\n* **KOReader：** 越狱后可以安装KOReader，这是一个功能丰富且可定制的电子书阅读器。\n* **文件传输：** Tailscale通过Taildrop提供便捷的文件传输方式，方便用户将电子书和其他文档导入Kindle。\n* **扩展可能性：** Tailscale可以连接到Tailnet网络，方便访问Home Assistant等服务，并搭建自托管的Calibre Web电子书库。\n\n**总而言之，** 在越狱的Kindle上安装Tailscale，可以显著提升设备的功能性和便利性，为用户带来更多自由和可能性。\n"},{"time":1765211888,"type":"story","descendants":54,"title":"Hunting for North Korean Fiber Optic Cables","id":46194384,"score":214,"url":"https://nkinternet.com/2025/12/08/hunting-for-north-korean-fiber-optic-cables/","by":"Bezod","summary":"## 北朝鲜互联网基础设施初步调查总结 (Preliminary Investigation Summary of North Korean Internet Infrastructure)\n\n本文档基于一份朝鲜民主主义人民共和国（DPRK）向国际民航组织（ICAO）提交的关于其航空业及ADS-B部署的演示文稿，以及其他公开信息，对朝鲜互联网基础设施的物理布局进行初步调查和推测。\n\n**核心发现:**\n\n* **光纤线路:** 演示文稿中显示一条跨越朝鲜的纤维光缆，这暗示朝鲜内部存在相对发达的光纤网络。\n* **与俄罗斯的连接:** 2017年，38North 报告了通过朝鲜-俄罗斯友谊桥与俄罗斯TTK之间的连接。照片显示在图们江附近，铁路旁存在埋设在草地中的基础设施，推测光缆可能埋在地下。\n* **早期光纤部署:** 报告显示，自1995年起，朝鲜陆续部署了多个光纤线路，包括平壤-咸兴、平壤-新义州、咸兴-罗先-首山、罗先-首山-珲春（中国）以及平壤-南浦等线路。2000年，朝鲜的光纤通信线路覆盖了所有省份。\n* **光网骨干网络 (Kwangmyong):**  Kwangmyong 是朝鲜国内主要内网，大部分公民通过该网络访问信息。 报告显示，光网的网络骨干容量为每秒 2.5 GB。\n* **铁路沿线可能为主要线路:** 根据对北朝鲜移动通信塔位置的分析，以及铁路地图，推测光纤线路主要沿朝鲜东海岸的平义铁路（Pyongra Line）铺设。在铁路无法铺设的区域，可能沿 AH 6/国道 7 号公路进行铺设。\n* **网络节点分布:** 基于 Kwangmyong 的地图，推测主要网络节点可能位于朝鲜东北部。\n* **与中国和俄罗斯的网络连接:**  朝鲜通过中国和俄罗斯分别拥有两个网络连接点。 175.45.176.0/24 段 IP 地址通过中国联通路由，175.45.177.0/24 段 IP 地址通过俄罗斯远东电信路由，而 175.45.178.0/24 段 IP 地址则双机房，可选择两种路由。\n* **网络延迟差异:** 通过traceroute测试发现，通过中国路由到达朝鲜境内的网络延迟较高，而通过俄罗斯路由的延迟较低，这可能暗示了俄罗斯连接点附近存在网络设备或数据中心。\n\n**技术细节:**\n\n* **主要线路:** 平壤 - 瓮山 - 咸兴 - 罗先 - 图们江，沿平义铁路和国道 7 号公路铺设。\n* **网络骨干:** Kwangmyong，容量为每秒 2.5 GB。\n* **连接方式:**  光纤线路，部分线路埋设在地下，可能沿铁路和公路铺设。\n* **IP 地址分配:**  通过中国和俄罗斯分别拥有两个网络连接点。\n\n**总结:**\n\n本文档基于现有信息，推测了朝鲜互联网基础设施的初步布局，并强调了许多推测是基于假设的。虽然缺乏官方数据，但通过分析公开信息，可以对朝鲜网络布局有一定了解。未来的研究需要进一步验证这些假设，并探索更多线索，以更全面地了解朝鲜互联网的实际情况。\n\n---\n\n### 了解更多关于朝鲜互联网的信息\n\n订阅以获取最新文章发送到您的电子邮件。\n"},{"time":1765209974,"type":"story","descendants":35,"title":"AMD GPU Debugger","id":46193931,"score":213,"url":"https://thegeeko.me/blog/amd-gpu-debugging/","by":"ibobev","summary":"好的，以下是您提供的内容的中文摘要，字数控制在800字以内，并使用Markdown格式：\n\n## GPU 调试器探索：从原理到实践\n\n本文记录了作者探索GPU调试器过程的心路历程，旨在解决CPU拥有成熟调试工具而GPU调试工具相对缺失的问题。作者受到rocmdb和Marcell Kiss博客的启发，尝试自行实现GPU调试器。\n\n**核心思路：**\n\n与CPU调试类似，GPU调试器需要能够暂停GPU执行，并允许检查GPU的当前状态。实现的关键在于与GPU直接通信，并能够触发中断（Trap）来暂停执行。\n\n**技术实现：**\n\n1. **与GPU通信：**\n   *  作者首先研究了RADV（Mesa 3D驱动程序）的工作方式，了解了与GPU通信的基础方法。\n   *  通过打开DRM文件（`/dev/dri/cardX`），建立与KMD（Kernel Mode Driver）的连接。\n   *  使用`libdrm`库作为中间层，与KMD交互，完成上下文创建、缓冲区分配和命令提交等操作。\n   *  缓冲区分配使用`amdgpu_bo_alloc`函数，并根据需求选择不同的内存域（GWS、GDS、OA）和标志（缓存、CPU访问等）。\n   *  内存映射使用`amdgpu_bo_va_op`函数，将缓冲区映射到GPU和CPU虚拟地址空间。\n2. **触发中断（Trap）：**\n   *  利用RDNA3架构中的`TBA`（Trap Base Address）和`TMA`（Trap Memory Address）寄存器，配置GPU在遇到特定异常时进入Trap Handler。\n   *  通过`AMDGPU Debugfs`接口，使用`regs2_ioc_data_v2`结构体，通过IOCTL调用向KMD写入这些寄存器的值。\n   *  文章详细描述了如何设置`TBA`和`TMA`，以及如何在Trap Handler中保存和恢复GPU状态。\n3. **Trap Handler：**\n   *  Trap Handler是一个特殊的shader程序，在GPU触发Trap时自动执行。\n   *  作者实现了一个简单的Trap Handler，使用`TTMP`寄存器保存GPU状态，并提供一个简单的循环等待CPU指令。\n   *  通过CPU指令控制GPU的暂停和恢复，实现基本的断点和单步调试功能。\n4. **SPIR-V编译：**\n   *  为了方便用户使用，作者利用RADV的编译器`ACO`，将SPIR-V代码编译成GPU可执行的机器码。\n   *  通过设置`RADV_FORCE_FAMILY`环境变量，模拟无Vulkan环境下的编译过程。\n5. **未来展望：**\n   *  作者计划进一步集成RADV，实现更强大的调试功能，例如：\n     *  在特定帧暂停执行。\n     *  基于Vulkan API调用进行调试。\n     *  利用调试信息（debug info）进行源代码级别的调试。\n     *  实现Watchpoint功能。\n\n**关键技术点：**\n\n*   **DRM接口:**  用于与GPU驱动程序通信。\n*   **libdrm库:** 作为用户态和内核态驱动之间的桥梁。\n*   **AMDGPU Debugfs:**  用于直接操作GPU的寄存器。\n*   **SPIR-V:**  GPU shader的标准中间表示。\n*   **Trap Handler:**  捕获异常并执行调试任务的特殊shader程序。\n\n**总结：**\n\n本文详细描述了作者探索GPU调试器的过程，从底层原理到具体实现，展示了通过直接与GPU交互，实现GPU调试的可能性。虽然目前的调试器功能有限，但为未来的GPU调试工具开发奠定了基础。\n"},{"time":1765238032,"type":"story","descendants":178,"title":"Kroger acknowledges that its bet on robotics went too far","id":46199411,"score":193,"url":"https://www.grocerydive.com/news/kroger-ocado-close-automated-fulfillment-centers-robotics-grocery-ecommerce/805931/","by":"JumpCrisscross","summary":"## 克罗格调整电商策略，关闭自动化配送中心\n\n**摘要:**\n\n克罗格公司近日宣布关闭三家机器人自动化电商配送中心 (Customer Fulfillment Center, CFC)，并对电商业务进行调整，标志着该公司在自动化电商领域的战略转变。此举旨在提高电商盈利能力，预计将带来4亿美元的收益，但同时将产生约26亿美元的费用。\n\n**主要内容：**\n\n*   **战略转变的背景:** 克罗格曾对与英国仓储自动化公司Ocado的合作充满信心，计划扩大自动化配送中心的规模，并引入新技术以提高效率。然而，随着项目未能达到预期业绩，克罗格开始重新评估其自动化策略。\n*   **逐步调整:** 克罗格此前已暂停Ocado项目的开发，并关闭了与机器人中心配合运作的三家“spoke”设施。\n*   **原因分析:**\n    *   **市场需求变化:** 疫情期间电商销售额激增后，消费者对电商的需求并未达到行业预期水平。\n    *   **配送速度的重要性:** 美国消费者更看重配送速度，Instacart和DoorDash等公司通过提供快速配送服务迅速发展。克罗格的自动化模式试图以合理的价格换取配送速度，但未能满足市场需求。\n    *   **地理位置问题:**  Ocado配送中心选址偏离城市中心，导致订单量不足，难以支撑高昂的自动化技术投资。\n*   **新的策略:** 克罗格将重心转向其遍布全国的2700多家超市，通过现有门店扩大快速配送能力，并深化与第三方配送公司的合作。同时，公司将试点在主要市场采用轻资产、基于门店的自动化技术。\n*   **对Ocado的影响:** 克罗格的战略调整对Ocado造成了重大打击，Ocado的股价大幅下跌，已回落至15年前首次公开募股时的水平。\n\n**总结:** 克罗格放弃大规模自动化电商配送中心，转而依靠现有门店和第三方合作，反映了电商市场变化和消费者对快速配送需求的转变。这一调整不仅对克罗格自身具有重要意义，也对Ocado的未来发展带来挑战。"},{"time":1765211570,"type":"story","descendants":118,"title":"Google confirms Android attacks; no fix for most Samsung users","id":46194315,"score":169,"url":"https://www.forbes.com/sites/zakdoffman/2025/12/08/google-confirms-android-attacks-no-fix-for-most-samsung-users/","by":"mohi-kalantari","summary":"## Android 安全更新紧急通知：三星用户需尽快关注\n\n**主要内容：**\n\n1.  **紧急安全更新：** Google于12月1日发布了紧急安全更新，针对Android系统中的漏洞CVE-2025-48633和CVE-2025-48572。Google确认这些漏洞正在被针对性地利用，可能导致远程拒绝服务攻击，且无需额外权限。\n2.  **Pixel用户优先：** Google首先向Pixel用户推送了更新，但针对大多数三星用户，相关修复程序尚未发布，尽管攻击已经开始。\n3.  **三星的回应：** 三星在Google发布警告后的数小时内确认并发布了相应的修复，并同时修复了Google Project Zero披露的另外三个漏洞。Project Zero致力于研究全球用户依赖的硬件和软件系统的零日漏洞。\n4.  **美国网络安全局 (CISA) 警告：** 在Google确认Android攻击的24小时后，CISA发布警告，要求联邦工作人员更新设备或停止使用，指出Android框架存在一个未具体说明的漏洞，可能导致权限提升。\n5.  **三星的市场地位：** 三星是Android市场上最大的厂商，其全球市场份额超过30%，几乎三分之一的Android用户选择三星手机。\n6.  **更新延迟问题：** 文章批评三星的更新周期过长，需要一个月的时间才能将关键修复程序部署到用户端，并且并非所有三星手机都能获得无缝更新（仅Galaxy S25和一款中端手机除外）。\n7.  **Android生态系统的局限性：** 三星及其他Android手机制造商无法与Google在硬件和软件控制上的优势相抗衡，因此Pixel和Apple手机通常能更快地获得系统更新和安全补丁。这解释了One UI 7和One UI 8（Android 15和16）的发布延迟。\n8.  **更新部署方式：** 三星的更新将按型号、地区和运营商分批进行部署，并非所有手机都能立即获得更新，即使它们在每月更新计划中。\n\n**总结：**\n\nAndroid系统正受到攻击，Google已发布紧急安全更新。尽管三星是Android市场份额最大的厂商，但由于Android生态系统的结构性问题，三星手机的更新速度相对较慢。用户需要尽快关注并更新设备，以防范安全风险。"},{"time":1765220448,"type":"story","descendants":317,"title":"Has the cost of building software dropped 90%?","id":46196228,"score":163,"url":"https://martinalderson.com/posts/has-the-cost-of-software-just-dropped-90-percent/","by":"martinald","summary":"## 软件开发行业面临颠覆性变革：代理编码带来的巨大经济影响 (软件开发行业面临颠覆性变革：代理编码带来的巨大经济影响)\n\n本文探讨了代理编码技术对软件开发行业及更广泛经济的潜在颠覆性影响，并预测其将在2026年引发重大变革。作者结合自身近20年软件开发经验，认为当前经济环境的变化，特别是代理编码的出现，将彻底改变软件开发模式。\n\n**核心观点：**\n\n*   **成本降低：** 代理编码技术能够显著降低软件开发的人工成本。作者以内部工具开发为例，指出传统模式需要数周时间，而使用代理编码工具，项目时长可缩短至一周，效率提升一个数量级。\n*   **需求激增：** 代理编码技术降低了软件开发的成本，将释放巨大的潜在需求。许多企业目前依赖Excel等低效工具管理业务流程，如果成本大幅降低，这些流程将更有可能被转化为SaaS应用。\n*   **领域知识成关键：** 代理编码工具需要人类进行监督和指导，确保代码质量。因此，开发者在特定领域和行业的知识将成为核心竞争力，能够更有效地利用工具解决业务问题。\n*   **快速迭代：** 代理编码技术使得软件开发变得更快速、更灵活，可以更快地迭代和调整方向，避免长期投入到错误的方向。\n*   **技术变革加速：** LLM模型不断进步，性能持续提升，对现有基准测试结果的解读需要重新评估。\n\n**关键细节：**\n\n*   **历史回顾：** 作者回顾了软件开发成本的变化历史，包括开源软件的兴起、云计算的普及以及近年来工程复杂度的增加。\n*   **Jevons悖论：** 借鉴Jevons悖论，指出成本降低并非导致需求减少，而是会激发更多需求。\n*   **传统开发模式的缺陷：** 作者批评了当前软件开发模式的过度复杂化，例如TDD、微服务、React前端和Kubernetes等，认为这些模式并未带来明显的成本降低。\n*   **代理编码工具的优势：** 代理编码工具能够将业务逻辑规范快速转化为高质量的API和Service，并能自动生成大量的单元/集成测试。\n*   **团队结构转变：** 代理编码技术将减少团队规模，更强调业务领域专家与开发者之间的紧密合作，而不是大型开发团队。\n*   **应对变革：** 呼吁软件工程师拥抱变革，积极学习和应用新的工具和技术，避免如2007年对iPhone的抵制一样，错失发展机遇。\n*   **维护现有代码库：** 代理编码工具不仅适用于新项目，还能有效理解和维护现有代码库，降低维护成本。\n\n**总结：**\n\n作者认为，代理编码技术是软件开发领域的一次变革性发展，将显著降低开发成本，释放大量潜在需求，并改变软件开发的模式和团队结构。 2026年将是关键年份，许多人可能会措手不及。 软件工程师需要积极拥抱变革，将领域知识作为核心竞争力，并与业务领域专家紧密合作，才能在新的时代中取得成功。\n"},{"time":1765256273,"type":"story","descendants":105,"title":"Modern Walkmans","id":46201381,"score":149,"url":"https://walkman.land/modern","by":"classichasclass","summary":"## 现代数字时代的卡带播放器：概述\n\n本文介绍了11款现代卡带播放器，它们将复古的卡带体验与现代技术相结合，满足了音乐爱好者的需求。以下是各型号的主要特点：\n\n**总体趋势:** 这些播放器都旨在复兴卡带音乐的魅力，并融合了蓝牙连接、USB供电等现代功能。\n\n**具体型号及特点:**\n\n* **Aurex AX-W10C (Toshiba):**  日本市场主销。无线蓝牙连接，虚拟环绕声，电池供电（约16小时）或USB供电，重量230g。\n* **Byron Statics KCS-315:**  支持FM/AM收音机，具有语音激活和自动停止功能，可使用2节AA电池或USB供电。\n* **DIGITNOW!:** 带有复古银色外壳，附带耳机，支持蓝牙传输音乐。\n* **FiiO CP13:** 注重音质，采用超低颤动，大尺寸纯铜飞轮，100%纯模拟声音和平衡放大头，以及高压电机电源。电池续航13小时。\n* **GPO:**  内置扬声器，可电池供电，方便携带。支持卡带播放和FM收音机。\n* **It's OK!:**  全球首款支持蓝牙5.0的卡带播放器，兼容3.5mm耳机和蓝牙设备。具有透明设计、蓝牙连接和内置麦克风。缺点是缺乏自动反转等便利功能，不包含耳机。\n* **Jensen:** 便携、轻巧、纤薄的设计，支持AM/FM收音机和天气广播，使用2节AA电池供电。\n* **Maxell MXCP-P100:**  支持蓝牙v5.4，采用黄铜飞轮以提高音质，内置电池，播放时间约为9小时，重量210g。\n* **Mulann B-1000 EW:**  价格实惠的便携式卡带播放器和录音机，支持双声道立体声播放。 频率响应：40Hz-11KHz (Type I)，信噪比：50dB，失真：1%，颤动：0.3%，耳机输出功率：2x2 mW into 32 ohms。\n* **TOMASHI F116/F113:** 入门级便携式卡带播放器。\n* **We Are Rewind:** 被描述为“最佳”卡带播放器，适合对音乐有要求的爱好者。\n\n**总结:** 这些现代卡带播放器在设计、功能和音质方面各不相同，旨在满足不同用户的需求，让经典卡带音乐在数字时代焕发新生。\n"},{"time":1765212282,"type":"story","descendants":16,"title":"A series of tricks and techniques I learned doing tiny GLSL demos","id":46194477,"score":137,"url":"https://blog.pkh.me/p/48-a-series-of-tricks-and-techniques-i-learned-doing-tiny-glsl-demos.html","by":"ibobev","summary":"## GLSL 演示技巧：回顾与学习 (GLSL Demo Tricks: A Review and Learning Journey)\n\n本文回顾了作者在过去两个月内创作的四个小型 GLSL 演示，分别是 Moonlight、Entrance 3、Archipelago 和 Cutie。文章旨在分享作者在创建这些演示过程中学到的经验，而非对每个细节进行深入剖析。\n\n**Moonlight (460 字符):**\n\n*   **新颖的体积光照技术:** Moonlight 演示展示了一种比传统体积光照更简单的技术，通过在光线追踪循环中将颜色贡献视为 `1/d` (d 为材质密度) 来实现。\n*   **物理基础:** 这种 `1/d` 的贡献基于光子密度遵循的逆平方定律，模拟了光子在空间中传播时的衰减。\n*   **透明度:** 通过调整公式 `d = A*abs(d)+B`，可以模拟物体透明度，其中 A 代表吸收，B 代表透射。\n\n**Entrance 3 (465 字符):**\n\n*   **L-∞ 范数:** 该演示使用了 L-∞ 范数（最大值范数）代替欧几里得范数，更适合于由立方体组成的场景。\n*   **实际光源:**  演示中使用了实际的光源，通过光线追踪重新定向光线方向，并根据是否击中固体来决定片段是否被照亮。\n*   **移动端 Bug:**  作者在移动设备上发现了 Snapdragon/Adreno 和 Imagination/PowerVR 驱动 bug，并针对性地修改了代码以解决这些问题。\n*   **Isometric (等角) 投影:** 演示中使用了等角投影，作者通过 Sympy 解决数学问题，推导出了等角和斜视投影的变换矩阵。\n\n**Archipelago (472 字符):**\n\n*   **程序化生成的环境:** Archipelago 演示创建了一个程序化的日本群岛环境。\n*   **波浪动画:**  使用了 `w=exp(sin(x))` 形式的噪声曲线进行波浪动画，通过 `x -= w*cos(x)` 来实现域扭曲效果。\n\n**Cutie (602 字符):**\n\n*   **Smoothmin 运算符:** 利用 Smoothmin 运算符创建了 Cutie 角色，通过两个不同大小的球体实现圆滑的锥形效果。\n*   **简单 IK 运动学:** 使用了简单的 IK 运动学来控制角色的动画。\n*   **迭代次数的利用:** 没有使用深度图，而是利用迭代次数来模拟视觉效果，使得光线穿过物体时速度变慢，从而突出物体的轮廓。\n\n**作者的创作理念：**\n\n作者坚持 512 字符的限制，认为这有助于：\n\n*   **学习支持:** 专注于少数几个关键技术点。\n*   **艺术表现:** 代码本身也是作品的一部分。\n*   **项目完成:** 限制降低了创作的复杂性，更容易完成。\n*   **个人乐趣:** 享受精巧的代码编写过程。\n*   **作品一致性:** 保持创作风格的一致性。\n\n作者通过 Mastodon 发布更新，并提供 RSS 订阅地址。"},{"time":1765220879,"type":"story","descendants":42,"title":"Trials avoid high risk patients and underestimate drug harms","id":46196308,"score":135,"url":"https://www.nber.org/papers/w34534","by":"bikenaga","summary":"## 工作论文 34534 摘要\n\n**标题:** 临床试验回避高风险患者并低估药物危害 (Trials Avoid High Risk Patients and Underestimate Drug Harms)\n\n**发布日期:** 2025年12月\n\n**DOI:** 10.3386/w34534\n\n**主要内容:**\n\n这份工作论文研究了临床试验参与度和癌症药物诱发不良事件（SAE）风险之间的关系。研究利用美国国家癌症登记处计划（Surveillance, Epidemiology, and End Results Program, SEER）与医疗保险（Medicare）索赔数据相结合的数据进行分析。\n\n**主要发现:**\n\n*   **药物治疗与SAE风险增加:** 启动癌症药物治疗会使因严重不良事件住院的风险每月增加2个百分点（增长250%）。\n*   **SAE治疗效应异质性:** 患者的合并症、虚弱程度和人口统计学特征可以预测SAE治疗效应的异质性。\n*   **高风险患者参与度低:** 风险分布中第90百分位数的患者在治疗后SAE风险增加2.5倍，但参与临床试验的可能性却少4倍。\n*   **试验参与者代表性不足:** 药物目标人群的SAE治疗效应预测结果比临床试验参与者高15%，相当于每治疗一年，每25名患者会增加1例药物诱发的SAE住院。\n\n**研究结论和建议:**\n\n研究结果表明，临床试验往往回避高风险患者，导致试验结果低估了药物的潜在危害。论文正式阐述了规范SAE风险代表性将如何提高试验外部有效性的条件，并讨论了研究结果如何为监管要求提供信息。\n\n**其他相关信息:**\n\n该研究由NBER（美国国家经济研究局）发布。此外，NBER还发布了其他活动，包括：\n\n*   **Feldstein Lecture:** 由N. Gregory Mankiw 主讲，主题为“财政未来”。\n*   **Methods Lectures:** 由Raj Chetty和Kosuke Imai 主讲，主题为“揭示因果机制：中介分析和替代指标”。\n*   **Panel Discussion:** 由Oleg Itskhoki、Paul R. Krugman 和 Linda Tesar 主讲，主题为“全球经济的未来”。\n"},{"time":1765213814,"type":"story","descendants":76,"title":"Launch HN: Nia (YC S25) – Give better context to coding agents","id":46194828,"score":121,"url":"https://www.trynia.ai/","by":"jellyotsiro","text":"Hi HN, I am Arlan and I am building Nia (<a href=\"https:&#x2F;&#x2F;trynia.ai\" rel=\"nofollow\">https:&#x2F;&#x2F;trynia.ai</a>), a context layer for AI coding agents. Nia lets tools like Cursor, Claude Code, and other MCP clients index and query real codebases and documentation so they stop hallucinating against outdated or wrong sources, with applications beyond coding agents to any AI system that requires grounded context across domains.<p>Coding agents are only as good as the context you give them. General models are trained on public code and documentation that is often old, and they usually have no idea what is inside your actual repo, internal wiki, or the exact version of a third party SDK you use. The result is very familiar: you paste URLs and code snippets into the prompt, the agent confidently uses an outdated API or the wrong framework version, and you spend more time verifying and correcting it than if you had written the code yourself. Once models are good enough at generating code, feeding them precise, up-to-date context becomes the bottleneck.<p>I ran into this pattern first on my own projects when (a few months ago) I was still in high school in Kazakhstan, obsessed with codegen tools and trying every coding agent I could find. I saw it again when I got into YC and talked to other teams who were also trying to use agents on real work.<p>The first version of Nia was basically “my personal MCP server that knows my repos and favorite doc sites so I do not have to paste URLs into Cursor anymore.” Once I saw how much smoother my own workflow became, it felt obvious that this should be a product other people could use too.<p>Under the hood, Nia is an indexing and retrieval service with an MCP interface and an API. You point it at sources like GitHub repositories, framework or provider docs, SDK pages, PDF manuals, etc. We fetch and parse those with some simple heuristics for code structures, headings, and tables, then normalize them into chunks and build several indexes: a semantic index with embeddings for natural language queries; a symbol and usage index for functions, classes, types, and endpoints; a basic reference graph between files, symbols, and external docs; regex and file tree search for cases where you want deterministic matches over raw text.<p>When an agent calls Nia, it sends a natural language query plus optional hints like the current file path, stack trace, or repository. Nia runs a mix of BM25 style search, embedding similarity, and graph walks to rank relevant snippets, and can also return precise locations like “this function definition in this file and the three places it is used” instead of just a fuzzy paragraph. The calling agent then decides how to use those snippets in its own prompt.\nOne Nia deployment can serve multiple agents and multiple projects at once. For example, you can have Cursor, Claude Code, and a browser based agent all pointed at the same Nia instance that knows about your monorepo, your internal wiki, and the provider docs you care about. We keep an agent agnostic session record that tracks which sources were used and which snippets the user accepted. Any MCP client can attach to that session id, fetch the current context, and extend it, so switching tools does not mean losing what has already been discovered.<p>A lot of work goes into keeping indexes fresh without reprocessing everything. Background workers periodically refetch configured sources, detect which files or pages changed, and reindex those incrementally. This matters because many of the worst “hallucinations” I have seen are actually the model quoting valid documentation for the wrong version. Fixing that is more about version and change tracking than about model quality.<p>We ship Nia with a growing set of pre-indexed public sources. Today this includes around 6k packages from common frameworks and provider docs, plus package search over thousands of libraries from ecosystems like PyPI, npm, and RubyGems, as well as pre indexed &#x2F;explore page where everyone can contribute their sources! The idea is that a new user can install Nia, connect nothing, and still get useful answers for common libraries. Then, as soon as you add your own repos and internal docs, those private sources are merged into the same index.\nSome examples of how people use Nia so far: - migrating from one payments provider or API version to another by indexing the provider docs plus example repos and letting the agent propose and iterate on patches; - answering “how do I do X in this framework” by indexing the framework source directly instead of relying only on official docs that might be stale; - turning an unfamiliar public codebase into a temporary wiki to self onboard, where you can ask structural questions and jump to specific files, functions, or commits; - building a browser agent that answers questions using up to date code and docs even when the public documentation lags behind.<p>Nia is a paid product (<a href=\"https:&#x2F;&#x2F;www.trynia.ai&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;www.trynia.ai&#x2F;</a>) but we have a free tier that should be enough for individuals to try it on real projects. Above that there is a self-serve paid plan for heavier individual use, and organization plans with higher limits, SOC 2, seat based billing, and options for teams that want to keep indexing inside their own environment. For private GitHub repos we can clone and index locally so code does not leave your infrastructure.<p>We store account details and basic telemetry like query counts and errors to operate the service, and we store processed representations of content you explicitly connect (chunks, metadata, embeddings, and small graphs) so we can answer queries. We do not train foundation models on customer content and we do not sell user data.\nMoreover, I can see Nia play out in the larger context of the agents space due to the global problem of providing reliable context to those systems. Early signals show that people are already using Nia for healthcare data, cloning Paul Graham by indexing all of his essays and turning him into an AI agent, using Naval’s archive to build a personalized agent, and more.<p>I would love to get Nia into the hands of more engineers who are already pushing coding agents hard and see where it breaks. I am especially interested in hearing about failure modes, annoying onboarding steps, places where the retrieval logic is obviously wrong or incomplete, or any security concerns I should address. I will be in the thread to answer questions, share more technical details, and collect any brutal feedback you are willing to give!","summary":"https://www.trynia.ai/"},{"time":1765210492,"type":"story","descendants":109,"title":"No more O'Reilly subscriptions for me","id":46194063,"score":114,"url":"https://zerokspot.com/weblog/2025/12/05/no-more-oreilly-subscriptions-for-me/","by":"speckx","summary":"## O’Reilly 订阅体验总结 (O’Reilly Subscription Experience Summary)\n\n以下是对原文内容的总结：\n\n作者在过去两年使用了 O’Reilly 的在线订阅服务，该服务提供无限访问 O’Reilly、Manning 等出版社的大量技术书籍、会议录像和网络研讨会等资源。\n\n**主要问题：**\n\n* **价值问题 (Value Issue):** 作者发现由于阅读速度较慢，无法充分利用订阅内容，使得每年 500 美元的订阅费用难以抵消。\n* **移动端体验问题 (Mobile Experience Issue):** O’Reilly 的移动应用存在可用性问题，包括：\n    * 同步不稳定 (Unstable Synchronization)。\n    * 被操作系统回收后，应用启动时经常回到首页，无法恢复到之前阅读的页面 (Frequent restarts to the home screen after being evicted)。\n    * 缺乏令人满意的阅读主题，不如 Apple Books 或 Kindle 应用 (Lack of enjoyable themes)。\n\n**最终决定：**\n\n作者很可能不会续订 O’Reilly 订阅服务。他认为，直接从 Kobo 等平台购买所需的书籍可能更划算，因为可以获得无 DRM 的 O’Reilly 书籍，并永久保留。\n\n**其他因素：**\n\n作者还注意到自己之前订阅的 Manning 服务还有未使用的积分。\n\n**总而言之，作者认为 O’Reilly 的订阅服务虽然资源丰富，但由于阅读速度和移动端体验问题，性价比不高，因此选择转向购买单本书籍的模式。**\n"},{"time":1765215193,"type":"story","descendants":60,"title":"We collected 10k hours of neuro-language data in our basement","id":46195109,"score":110,"url":"https://condu.it/thought/10k-hours","by":"nee1r","summary":"## 运行数据收集 20 小时/天，我们从操作和机器学习中学习到的东西\n\n**摘要:**\n\n这篇博文描述了 Conduit 如何收集了大约 10,000 小时的神经语言数据，这被认为是世界上最大的此类数据集。他们通过让数千人每天 20 小时在地下室的展位中与大型语言模型 (LLM) 进行对话来完成这一壮举。\n\n**主要内容：**\n\n*   **数据收集过程:**参与者签署同意书，然后在展位中与 LLM 进行自由对话两小时。会话类型包括听/说和读/写。通过 Deepgram 进行音频转录，OSS120B 在 Cerebras 上运行 LLM 响应，ElevenLabs 为某些回复配音。他们使用积分系统奖励高质量的参与。\n*   **硬件和软件:**他们使用定制的多模态耳机，结合了来自不同供应商的最佳单模态耳机。数据存储和处理使用 Zarr 3 格式。\n*   **关键学习:**\n    *   **噪音:** 随着数据集规模的扩大，噪音的影响减弱。他们放弃了耗时的降噪技术，例如使用凝胶，并专注于增加数据量。\n    *   **操作规模化:** 优化了预订系统（使用动态定价和超额预订）和会话流程，以提高效率。\n    *   **参与者:**  通过 Craigslist 招募参与者，并建立参与者大使计划。\n*   **展位设计:**  他们尝试了各种展位设置，包括最初的独立房间、声学处理过的录音室和最终定制的隔音展位。\n*   **未来的工作:** Conduit 正在专注于训练模型并寻找有兴趣使用他们数据集的合作伙伴。\n\n**核心要点:**\n\n*   收集大规模神经语言数据集需要精心策划的操作和技术。\n*   随着数据集规模的扩大，降噪变得不那么重要，而数据量变得更加重要。\n*   优化预订系统和会话流程对于高效的数据收集至关重要。\n*   持续改进参与者招募和激励策略对于确保数据质量至关重要。\n\n**总而言之，** 这篇博文提供了一个关于大规模神经语言数据集收集的宝贵见解，强调了数据收集的运营和机器学习方面的考虑因素。\n"},{"time":1765215514,"type":"story","descendants":112,"title":"AI should only run as fast as we can catch up","id":46195198,"score":108,"url":"https://higashi.blog/2025/12/07/ai-verification/","by":"yuedongze","summary":"## 人工智能的运行速度不应超过我们理解的速度\n\n这篇文章探讨了人工智能在软件开发中的应用，并提出了一个关键观点：人工智能的运行速度应该受到我们理解和验证其工作速度的限制。作者通过两个朋友的故事，以及对人工智能任务分解为学习/创造和验证两个阶段的分析，阐述了这一观点。\n\n**故事背景：**\n\n* **Eric的故事：** Eric使用Gemini快速生成Web应用原型，但缺乏对底层技术的理解，难以将其转化为可靠的企业级产品。他试图跳过常规的开发步骤，直接将其推向生产环境，但由于缺乏对代码的深入理解，最终未能成功。\n* **Daniel的故事：** Daniel则是一位资深工程师，他利用人工智能生成代码组件，并进行快速验证，确保其符合现有框架和规范。他通过简单的测试和代码审查，将人工智能生成的功能顺利推入生产环境，效率显著提高。\n\n**核心观点：**\n\n作者认为，这两个故事揭示了一个普遍的问题：**如何让人工智能可靠地工作**。人工智能的学习和思考速度远超人类，但要使其真正有用，我们需要跟上人工智能的工作节奏，及时验证其结果。\n\n**验证的重要性：**\n\n作者将任务分解为学习/创造和验证两个阶段，并指出验证的难易程度对人工智能应用至关重要：\n\n* **验证 << 学习/创造：** 可以有效验证人工智能的工作，结果可靠。例如，图像生成，人们可以凭借直觉快速判断图像质量。\n* **验证 ≈ 学习/创造：** 验证工作与创造工作耗时相当，人工智能的效率提升有限。\n* **验证 >> 学习/创造：** 难以确定人工智能的工作是否正确，容易陷入“感觉”的困境，可靠性降低。\n\n**验证债务（Verification Debt）：**\n\n当验证工作变得复杂，需要领域知识、技术专长和行业经验时，就会产生“验证债务”。大量未经验证的代码积累，可能导致意想不到的副作用和风险。作者认为，验证债务是技术领导者需要关注的重要问题。\n\n**验证工程（Verification Engineering）：**\n\n作者认为，验证工程将成为继提示工程和上下文工程之后的下一个重要领域。通过优化任务流程、使用抽象和框架，可以简化人工智能工作成果的验证，从而提升产品的可靠性。\n\n**未来展望：**\n\n作者认为，能够有效验证复杂任务的人工智能应用将获得最大的收益。未来可能需要抛弃传统的编程语言，采用更抽象的数据流表示，以便更容易地验证任务的正确性。 最终，人们可能会像《Severance》中那样，通过对屏幕上数据的直觉判断来控制人工智能，利用人类的直觉进行高效的工作。\n\n**总结：**\n\n人工智能的潜力巨大，但其可靠性取决于我们验证其工作成果的能力。我们需要关注验证工程，并不断提升验证工作的效率，才能充分利用人工智能的优势，构建可靠、负责任的系统。\n"},{"time":1765215595,"type":"story","descendants":31,"title":"Quanta to publish popular math and physics books by Terence Tao and David Tong","id":46195225,"score":107,"url":"https://www.simonsfoundation.org/2025/12/08/quanta-books-to-publish-popular-math-and-physics-titles-by-terence-tao-and-david-tong/","by":"digital55","summary":"## 量塔图书宣布两本新书，作者为陶哲轩和汤大卫\n\n**摘要:** 量塔图书 (Quanta Books) 宣布将出版两位杰出学者的两本新书：数学家陶哲轩 (Terence Tao) 和理论物理学家汤大卫 (David Tong)。这两本书旨在以通俗易懂的方式向大众介绍重要的科学概念。\n\n**书籍详情:**\n\n*   **《数学六要点》(Six Math Essentials) - 陶哲轩:** 这是陶哲轩的第一本面向大众的数学书籍。书中将探讨六个对数学发展至关重要的核心思想，旨在消除数学的神秘感和难度，让更多人理解数学在现代世界的重要性。该书将涵盖以下六个方面：\n    *   数字：作为定量思维的入口\n    *   代数：作为抽象思维的入口\n    *   几何：超越可见之物\n    *   概率：在不确定性中进行严谨思考的工具\n    *   分析：处理极大或极小的手段\n    *   动力学：变化的数学\n    预计2026年11月在美国书店发售，并将翻译成中文、法语、希腊语、意大利语、波兰语等多种语言。\n\n*   **《万物皆为场》(Everything Is Fields) - 汤大卫:** 这本书将深入浅出地介绍量子场论 (Quantum Field Theory, QFT)，这是解释宇宙基本构成要素的物理理论。汤大卫将阐释粒子和力的统一性，指出物质、光乃至人类自身，都是弥漫于整个宇宙的“量子场”上的波动。\n\n*   **《代码中的证明》(The Proof in the Code) - 凯文·哈特内特:** 这本书是关于微软开发的证明助手Lean的诞生和崛起的权威记录。Lean最初被设计为代码检查程序，但后来被数学家们意识到其强大的潜力，可以成为一个“真理预言家”，帮助验证或证伪任何复杂的数学或逻辑命题。这本书探讨了计算机在数学领域的作用，以及人工智能的未来。该书已于2026年6月出版，现可预订。\n\n**关于量塔图书:**\n\n量塔图书是西蒙斯基金会 (Simons Foundation) 的一个编辑独立子公司，与法拉·施特劳斯和吉罗出版社 (Farrar, Straus and Giroux) 合作。该出版社致力于用艺术化的叙事方式，向读者阐释现代科学的核心问题和基本思想，以期加深人们对宇宙的理解。\n\n**联系方式:** [email protected]\n"},{"time":1765239995,"type":"story","descendants":59,"title":"Horses: AI progress is steady. Human equivalence is sudden","id":46199723,"score":106,"url":"https://andyljones.com/posts/horses.html","by":"pbui","summary":"## 人工智能的快速发展：一场如同马车被汽车取代的变革\n\n这是一篇2025年夏季小型研讨会上发表的五分钟闪电演讲，讲述了人工智能的快速发展及其对个人的影响。演讲者，Anthropic的早期研究人员，通过对比历史上的马匹、国际象棋以及自身的工作经历，阐述了人工智能发展的速度和潜在的颠覆性。\n\n**1. 历史类比：马匹与引擎的演变**\n\n演讲首先以马匹为例，说明了技术进步的渐进性和其对个体的影响滞后性。从1700年开始，蒸汽机技术经历了200年的持续改进，效率每十年提升20%。然而，在最初的120年里，马匹对此毫无察觉。直到1930-1950年间，由于引擎技术的突飞猛进，美国境内90%的马匹消失了。\n\n**2. 国际象棋：人工智能超越人类的进程**\n\n随后，演讲者将视角转向国际象棋，展示了计算机国际象棋水平的进步。从1985年开始，计算机的Elo等级每年提升50分。到2000年，人类国际象棋大师与计算机对弈时，胜率高达90%。十年后，胜率反转，大师输给计算机的概率也达到了90%。这表明人工智能在特定领域超越人类的速度相对较快。\n\n**3. 人工智能的发展现状：持续的投入与指数级增长**\n\n演讲者用图表展示了人工智能领域的资本支出情况。目前，全球每年在人工智能数据中心方面的支出相当于美国GDP的2%，并且这一数字在过去几年中呈现倍增趋势，预计未来几年将继续保持这一增长。\n\n**4. 个人经历：被AI取代的现实**\n\n演讲者结合自身经历，讲述了人工智能对自身工作的影响。他曾负责解答Anthropic新员工的技术问题，每月回答约4000个问题。但随着Claude（一个AI语言模型）的进步，到2024年12月，Claude已经能够胜任部分解答工作。仅仅六个月后，Claude就能够处理80%之前由他解答的问题，每月回答30000个问题，是之前团队的八倍。\n\n**5. 成本效益：AI的巨大优势**\n\n演讲者强调了AI在成本效益方面的巨大优势。Claude的成本是他的千分之一，且每生成一个词的成本低于地球上最廉价的人工劳动。\n\n**6. 对未来的展望：警惕快速变革**\n\n演讲者再次以马匹的例子进行类比，指出1920年美国有2500万马匹，它们对机械引擎的200年进步毫不知情。随后，93%的马匹消失了。演讲者希望自己能像马匹一样拥有20年的缓冲期，但考虑到Claude快速自动化其工作的速度，他认为实际情况可能会更短。\n\n**总结：**\n\n演讲的核心观点是，人工智能的发展速度正在加速，其对人类社会和个人的影响可能比以往任何技术变革都更加迅速和深刻。 演讲者希望人们能够意识到这种变革的潜在影响，并做好相应的准备。\n"},{"time":1765223921,"type":"story","descendants":58,"title":"GitHub no longer uses Toasts","id":46196831,"score":106,"url":"https://primer.style/accessibility/toasts/","by":"samsolomon","summary":"## GitHub 推荐避免使用 Toast 通知：可访问性和可用性问题\n\n这份文档概述了关于 Toast 通知（屏幕上弹出的小型矩形通知）的潜在问题，并建议 GitHub 开发者避免使用它们，而选择更有效且可访问的替代方案。\n\n**核心问题：**\n\nToast 通知存在显著的可访问性和可用性问题，GitHub 强烈建议避免使用，并推荐其他更可靠的沟通方式。\n\n**替代方案：**\n\n根据不同的使用场景，GitHub 建议采用以下替代方案：\n\n*   **简单直接的成功操作:**  例如创建 Issue，直接在 Issue 列表上显示新创建的 Issue，无需额外通知。\n*   **复杂操作的成功反馈:**  例如批量创建 Issue，可以使用 Banner 或渐进式内容展示来提供反馈。\n*   **失败操作的反馈:** 使用 Banner 或 Dialog 提示错误信息。Dialog 更适合需要用户立即关注的情况。\n*   **表单提交反馈:** 简单的表单提交可以直接显示结果，复杂的表单可以使用 Banner 或确认页面。\n*   **长时间运行的任务:** 使用 Banner 提示任务完成或失败，并考虑通过邮件、通知或 GitHub 应用推送等其他渠道通知用户。\n*   **应用状态同步:** 使用 Banner 或 Dialog 提示用户需要刷新页面以同步客户端和服务器状态。\n\n**可访问性考虑：**\n\nToast 通知违反了多个 Web 内容可访问性指南 (WCAG) 的成功标准，包括：\n\n*   **2.2.1 定时可调整：** 需要提供延长 Toast 显示时间的功能，允许用户充分阅读和操作。\n*   **1.3.2 语义顺序：** Toast 消息的位置可能与触发它的代码存在脱节，影响辅助技术的理解。\n*   **2.1.1 键盘：** Toast 中的交互元素需要支持键盘操作，包括关闭 Toast 本身。\n*   **4.1.3 状态消息：** Toast 需要以不干扰用户正常工作的方式通知辅助技术。\n\n**其他可访问性问题：**\n\n文档还指出了 Toast 通知在文本缩放、页面重排、键盘焦点顺序、内容一致性等方面可能存在的问题。\n\n**可用性考虑：**\n\n除了可访问性问题，Toast 通知还存在以下可用性问题：\n\n*   **大屏幕显示：** 可能在用户的视野之外。\n*   **分散注意力：** 自动消失的 Toast 容易被忽略。\n*   **遮挡 UI：** 可能会遮挡重要的 UI 元素，例如表单提交按钮。\n*   **屏幕放大：** 某些用户可能无法看到。\n*   **工作记忆：** 自动消失的 Toast 可能会导致用户无法回顾重要信息。\n*   **Banner Blindness：** 过度使用导致用户忽略。\n*   **内容分离：** Toast 位置远离触发它的 UI 元素，降低用户理解关联性。\n*   **意外关闭：** 用户可能意外关闭 Toast 或其他 UI 元素。\n\n**总结：**\n\n由于可访问性和可用性方面的诸多问题，GitHub 建议开发者避免使用 Toast 通知，并选择更可靠、更易访问的替代方案，以提升用户体验。\n"},{"time":1765232486,"type":"story","descendants":84,"title":"Show HN: I built a system for active note-taking in regular meetings like 1-1s","id":46198430,"score":105,"url":"https://withdocket.com","by":"davnicwil","text":"Hey HN! Like most here regular meetings have always been a big part of my work.<p>Over the years I&#x27;ve learned the value of active note taking in these meetings. Meaning: not minutes, not transcriptions or AI summaries, but <i>me</i> using my brain to actively pull out the key points in short form bullet-like notes, as the meeting is going on, as I&#x27;m talking and listening (and probably typing with one hand). This could be agenda points to cover, any interesting sidebars raised, insights gotten to in a discussion, actions agreed to (and a way to track whether they got done next time!).<p>It&#x27;s both useful just to track what&#x27;s going on in all these different meetings week to week (at one point I was doing about a dozen 1-1s per week, and it just becomes impossible to hold it in RAM) but also really valuable over time when you can look back and see the full history of a particular meeting, what was discussed when, how themes and structure are changing, is the meetings effective, etc.<p>Anyway, I&#x27;ve tried a bunch of different tools for taking these notes over the years. All the obvious ones you&#x27;ve probably used too. And I&#x27;ve always just been not <i>quite</i> satisfied with the experience. They work, obviously (it&#x27;s just text based notes at the end of the day) but nothing is first-class for this usecase.<p>So, I decided to build the tool I&#x27;ve always felt I want to use, specifically for regular 1-1s and other types of regular meetings. I&#x27;ve been using it myself and with friends for a while already now, and I think it&#x27;s got to that point where I actually prefer to reach for it over other general purpose note taking tools now, and I want to share it more widely.<p>There&#x27;s a free tier so you can use it right away, in fact without even signing up.<p>If you&#x27;ve also been wanting a better system to manage your notes for regular meetings, give it a go and let me know what you think!","summary":"Okay, I'm ready. Please provide the content you want me to summarize. I will do my best to generate a concise and accurate summary in markdown format and Chinese language, adhering to your specified constraints (less than 800 words, no personal opinions, and focusing on purpose, structure, and functionality for technical content).  Just paste the content here, and I'll get started.\n"}]